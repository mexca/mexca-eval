{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Mexca's video subcomponent on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this notebook is run on google colab so that we can use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pyannote.audio requirements\n",
    "!pip install -qq torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 torchtext==0.12.0\n",
    "!pip install -qq speechbrain==0.5.12\n",
    "\n",
    "# install pyannote.audio\n",
    "!pip install -qq pyannote.audio\n",
    "\n",
    "# install huggingface to download pyannote's models\n",
    "!pip -qq install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub import notebook_login\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.database.util import load_rttm\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate, DiarizationCoverage, DiarizationPurity\n",
    "from pyannote.core import Annotation, Segment\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login() #insert token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@develop\", use_auth_token=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\",\n",
    "                                    use_auth_token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/content/list_audio_.txt','r')\n",
    "\n",
    "for filepath in f.readlines():\n",
    "  print(f'Computing video @ {filepath} ...')\n",
    "  n_speakers = int(filepath.strip().split(\"/\")[-1].split(\"_\")[2])\n",
    "  t_duration = int(filepath.strip().split(\"/\")[-1].split(\"_\")[3])\n",
    "  print(n_speakers)\n",
    "  print(t_duration)\n",
    "  diarization = pipeline(filepath.strip(),  num_speakers= n_speakers)\n",
    "  t = open(f\"{n_speakers}_{t_duration}.rttm\",\"w\")\n",
    "  diarization.write_rttm(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mexca_october_22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "001e1c0fa8f3df81934e2d8f25d5607606c89bdb27a35bc13df9b3192171a0f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
