{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Mexca's video subcomponent on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this notebook is run on [google colab](https://colab.research.google.com/drive/1OLSfQX8xqw0jztRY-MDUIZ178vqBceMO?usp=sharing) so that we can use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pyannote.audio requirements\n",
    "!pip install -qq torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 torchtext==0.12.0\n",
    "!pip install -qq speechbrain==0.5.12\n",
    "\n",
    "# install pyannote.audio\n",
    "!pip install -qq pyannote.audio\n",
    "\n",
    "# install huggingface to download pyannote's models\n",
    "!pip -qq install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub import notebook_login\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.database.util import load_rttm\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate, DiarizationCoverage, DiarizationPurity\n",
    "from pyannote.core import Annotation, Segment\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login() #insert token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@develop\", use_auth_token=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pyannote on list of audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/content/list_audio_.txt','r')\n",
    "\n",
    "for filepath in f.readlines():\n",
    "  print(f'Computing video @ {filepath} ...')\n",
    "  n_speakers = int(filepath.strip().split(\"/\")[-1].split(\"_\")[2])\n",
    "  t_duration = int(filepath.strip().split(\"/\")[-1].split(\"_\")[3])\n",
    "  print(n_speakers)\n",
    "  print(t_duration)\n",
    "  diarization = pipeline(filepath.strip(),  num_speakers= n_speakers)\n",
    "  t = open(f\"{n_speakers}_{t_duration}.rttm\",\"w\")\n",
    "  diarization.write_rttm(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all rttm files (both reference and pyannote's output) and find the optimal mapping between labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/content/list_reference.txt','r')\n",
    "t = open('/content/list_mexca.txt','r')\n",
    "\n",
    "metric = DiarizationErrorRate(collar=.25)\n",
    "\n",
    "for filepath,mexca_path in zip(f.readlines(),t.readlines()):\n",
    "  print(mexca_path)\n",
    "  print(filepath)\n",
    "\n",
    "  n_speakers = int(mexca_path.strip().split(\"/\")[-1].split(\"_\")[0])\n",
    "  t_duration = int(mexca_path.strip().split(\"/\")[-1].split(\"_\")[1].split(\".\")[0])\n",
    "\n",
    "  print(n_speakers)\n",
    "  print(t_duration)\n",
    "\n",
    "  REFERENCE = filepath.strip()\n",
    "  reference = load_rttm(REFERENCE)\n",
    "\n",
    "  MEXCA = mexca_path.strip()\n",
    "  mexca = load_rttm(MEXCA)\n",
    "\n",
    "  optimal_dict = metric.optimal_mapping(reference[\"sample\"], mexca[f\"list_audio_{n_speakers}_{t_duration}_unbalanced\"])\n",
    "  \n",
    "  df = pd.DataFrame(optimal_dict.items()) \n",
    "  df['file'] = f\"list_audio_{n_speakers}_{t_duration}_unbalanced\"\n",
    "  df.to_csv(f'mapping_{n_speakers}_{t_duration}.txt', header=None, index=None, sep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mexca_october_22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "001e1c0fa8f3df81934e2d8f25d5607606c89bdb27a35bc13df9b3192171a0f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
